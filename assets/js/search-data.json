{
  
    
        "post0": {
            "title": "Interrupted Time Series (ITS) in Python",
            "content": ". Motivation . When A/B test is not an option . The gold standard for statistically asserting the effectiveness of an intervention is the randomized controlled experiment and its simplified online variant: the A/B test. . . üìù During an A/B test there are two almost identical versions of a product, simultaneously running, that only differ by the hypothesis you want to test ( i.e can a red call to action button convert more than a blue one? ). Users are randomly chosen to experience one (and only one) of the two versions while the experiment is active. . . They are easy to understand, easy to setup (great free tools easily available) and when correctly designed they rule out any covariate differences between the groups. . However, sometimes it‚Äôs just not possible to set up an A/B test: . Technical difficulties. Sometimes a change is so widespread and complex that it would be technically impossible to keep two different versions running simultaneously. . | Business strategy. A new feature rollout will be available first to some countries and later for others. . | Ethical concerns. Having a subset of customers having access to a feature or bug fix that gives them a competitive advantage over others that don‚Äôt. . | Legal or regulatory requirements. A change in regulations becomes mandatory ( i.e. GPDR compliance ) and should be applied to all your customers of a given country at the same time. . | Temporal infeasibility. You want to analyze an event that has already happened ( i.e. How last Google‚Äôs search algorithm update impacted your sales funnel? ). . | . Quasi Experiments . . If you can‚Äôt do an A/B test then the second to best alternative are quasi experiments [1]. . In a quasi experiment, your treatment and control group are not divided by a completely random process but by a natural process (i.e. time, location, etc) therefore there is a much larger chance for imbalance due to skewness and heterogeneous differences. The results of a quasi-experiment won‚Äôt be as precise as an A/B, but if carefully conducted could be considered close enough to compute estimates. . There are some scenarios, like some described in the previous section, where having a control group in parallel to a test group is just not possible, and this is when Interrupted Times Series comes in very handy. . Interrupted Time Series (ITS) . Interrupted time series (ITS) is a method of statistical analysis involving tracking a period before and after a intervention at a known point in time to assess the intervention‚Äôs effects within a single group/population. The time series refers to the data over the period, while the interruption is the intervention, which is a controlled external influence or set of influences. Effects of the intervention are evaluated by changes in the level and slope of the time series and statistical significance of the intervention parameters[2]. The more observations you have before and after the intervention, the more robust your model will be (typically). Because the evaluation is based on observing a single population over time, the ITS design is free from problems due to between-group difference but are susceptible to time-varying confounders like other interventions occurring around the time of the intervention that may also affect the outcome[3]. . . . üëç Strengths of Interrupted Time Series include the ability to control for secular trends in the data (unlike a 2-period before-and-after $t$-test), ability to evaluate outcomes using population-level data, clear graphical presentation of results, ease of conducting stratified analyses, and ability to evaluate both intended and unintended consequences of interventions. . üëé Limitations of Interrupted Time Series include the need for a minimum of 8 time periods before and 8 after an intervention to evaluate changes statistically, difficulty in analyzing the independent impact of separate components of a program that are implemented close together in time, and existence of a suitable control population. . . In mathematical terms, it means that the time series equation $(1)$ includes four key coefficients: . Y=b0+b1T+b2D+b3P+œµY = b_0 + b_1T + b_2D + b_3P + epsilonY=b0‚Äã+b1‚ÄãT+b2‚ÄãD+b3‚ÄãP+œµ . Where: . $Y$ is the outcome variable; . $T$ is a continuous variable which indicates the time passed from start of the observational period; . $D$ is a dummy variable indicating observation collected before ($D=0$) or after ($D=1$) the intervention; . $P$ is a continuous variable indicating time passed since the intervention has occurred (before intervention has occurred $P$is equal to $0$); . With $ epsilon$ representing a zero centered gaussian random error. . Counterfactual . . What would have happened had Neo chosen the blue pill? In an ITS it is important to understand the counterfactual. The counterfactual refers to what it would have occurred to Y, had the policy intervention not happened. . . üìùCounterfactuals are simply ways of comparing what happens given a change, versus what should have happened had some change not occurred in the first place. . . In a randomized trial or A/B test we know the counterfactual average outcome because the experiment withheld the intervention from the control group (which by randomization is somewhat the same as the intervention group). A critical assumption in ITS is that the outcome of interest trend would remain unchanged in the absence of intervention. . A practical example . Bob runs a large and successful blog on personal finance. During a webinar he learns that making his web content load faster could reduce its bounce rate and therefore decides to sign up for a CDN service. It‚Äôs been 6 months since he added a CDN to his blog and he wants to know if the investiment he did reduced the bounce rate. . Dataset . Bob provides us with üíæ 24 weeks of data before adding the CDN and 24 weeks after it (intervention). Therefore, weeks 1 to 24 have a bouncing rate before intervention and weeks 25 to 48 after it. . . . Visually, it looks like after enabling the CDN the bounce rate decreased, but by how much, and does it have statistical significance? To answer this question using interrupted time series analysis, we first need to prepare our data. . Dataset preparation . Using equation eqref{eq:its} notation we üíæ enrich this data with values for columns $D$ ($0$ = before intervention, $1$ after) and $P$ (number of weeks since intervention started): . Bouncing rate(Y) Week (T) Intervention(D) Intervention week(P) . 12.92 | 1 | 0 | 0 | . 13.03 | 2 | 0 | 0 | . 13.06 | 3 | 0 | 0 | . 13.17 | 4 | 0 | 0 | . ‚Ä¶ | ‚Ä¶ | ‚Ä¶ | ‚Ä¶ | . 12.04 | 45 | 1 | 21 | . 12.45 | 46 | 1 | 22 | . 12.74 | 47 | 1 | 23 | . 12.57 | 48 | 1 | 24 | . Naive solution . Let‚Äôs implement an ordinary least squares (OLS) regression using statsmodels to measure the impact of our intervention: . import pandas as pd import statsmodels.api as sm import statsmodels.formula.api as smf df = pd.read_csv(&quot;enriched_data.csv&quot;) model = smf.ols(formula=&#39;Y ~ T + D + P&#39;, data=df) res = model.fit() print(res.summary()) . With output: . OLS Regression Results ============================================================================== Dep. Variable: Y R-squared: 0.666 Model: OLS Adj. R-squared: 0.643 Method: Least Squares F-statistic: 29.18 Date: Tue, 28 Dec 2021 Prob (F-statistic): 1.52e-10 Time: 14:33:50 Log-Likelihood: 4.8860 No. Observations: 48 AIC: -1.772 Df Residuals: 44 BIC: 5.713 Df Model: 3 Covariance Type: nonrobust ============================================================================== coef std err t P&gt;|t| [0.025 0.975] Intercept 12.9100 0.096 134.225 0.000 12.716 13.104 T 0.0129 0.007 1.920 0.061 -0.001 0.026 D -0.5202 0.132 -3.942 0.000 -0.786 -0.254 P -0.0297 0.010 -3.115 0.003 -0.049 -0.010 ============================================================================== Omnibus: 3.137 Durbin-Watson: 0.665 Prob(Omnibus): 0.208 Jarque-Bera (JB): 1.995 Skew: 0.279 Prob(JB): 0.369 Kurtosis: 2.172 Cond. No. 125. ============================================================================== . The model estimates that the bounce rate decreased üîª 0.52% and this effect is statistically significant ($P&gt;|t|$ is virtually zero). . It is also noteworth that the model estimates a small (on average üîª 0.0297%) but with statistical significance trend of a decrease in bounce rate each week after intervention, which is unexpected since the CDN serves the whole website just a few hours after activation. . The figure below depicts how the model fits before and after intervention and how it project a counterfactual would be: . start = 24 end = 48 beta = res.params # Get model predictions and 95% confidence interval predictions = res.get_prediction(df) summary = predictions.summary_frame(alpha=0.05) # mean predictions y_pred = predictions.predicted_mean # countefactual assumes no interventions cf_df = df.copy() cf_df[&quot;D&quot;] = 0.0 cf_df[&quot;P&quot;] = 0.0 # counter-factual predictions cf = res.get_prediction(cf_df).summary_frame(alpha=0.05) # Plotting plt.style.use(&#39;seaborn-whitegrid&#39;) fig, ax = plt.subplots(figsize=(16,10)) # Plot bounce rate data ax.scatter(df[&quot;T&quot;], df[&quot;Y&quot;], facecolors=&#39;none&#39;, edgecolors=&#39;steelblue&#39;, label=&quot;bounce rate data&quot;, linewidths=2) # Plot model mean bounce rate prediction ax.plot(df[&quot;T&quot;][:start], y_pred[:start], &#39;b-&#39;, label=&quot;model prediction&quot;) ax.plot(df[&quot;T&quot;][start:], y_pred[start:], &#39;b-&#39;) # Plot counterfactual mean bounce rate with 95% confidence interval ax.plot(df[&quot;T&quot;][start:], cf[&#39;mean&#39;][start:], &#39;k.&#39;, label=&quot;counterfactual&quot;) ax.fill_between(df[&quot;T&quot;][start:], cf[&#39;mean_ci_lower&#39;][start:], cf[&#39;mean_ci_upper&#39;][start:], color=&#39;k&#39;, alpha=0.1, label=&quot;counterfactual 95% CI&quot;); # Plot line marking intervention moment ax.axvline(x = 24.5, color = &#39;r&#39;, label = &#39;intervention&#39;) ax.legend(loc=&#39;best&#39;) plt.ylim([10, 15]) plt.xlabel(&quot;Weeks&quot;) plt.ylabel(&quot;Bounce rate (%)&quot;); . . . Problems with naive approach . . . OLS (Ordinary Least Squares) regression has seven main assumptions but for brevity in this article we will focus on two only: . Individual observations are independent. | Residuals follow a normal distribution. | . Let‚Äôs first check for the normality of residuals: . We can apply the Jarque-Bera test on residuals to checks whether their skewness and kurtosis match a normal distribution ($H_0$: residual distribution follows a normal distribution). Our statsmodels OLS summary output shows a Prob(JB): 0.369 which for a standard $ alpha$ level of 0.05 doesn‚Äôt allow us discard null hypothesis ($H_0$). . Let‚Äôs plot the distribution of residuals: . res.resid.plot(kind=&quot;kde&quot;) . . . Which for a small dataset (less than 50 points) looks sufficiently gaussian. . Overall, the assumption of normality of residuals can‚Äôt be convincingly refuted. ‚úÖ . Checking independence of observations: . The Durbin-Watson statistic test if the residuals are correlated with its immediate predecessor, that is, if they have an autocorrelation at lag 1 or $AR(1)$. Its value ranges from 0 to 4 and values smaller than 1.5 indicate a positive autocorrelation, while values greater than 2.5 signal a negative autocorrelation. . If we take a look again at our OLS summary output we will observe that the Durbin-Watson statistic has a value of 0.665 which signals a strong positive $AR(1)$. . Let‚Äôs plot the residuals to see if we can observe this autocorrelation: . import altair as alt rules = alt.Chart(pd.DataFrame({ &#39;residuals&#39;: [0.0], &#39;color&#39;: [&#39;black&#39;] })).mark_rule().encode( y=&#39;residuals&#39;, color=alt.Color(&#39;color:N&#39;, scale=None) ) residual_plot = alt.Chart(res_df).mark_point().encode( x=alt.X(&#39;Weeks&#39;), y=alt.Y(&#39;residuals&#39;) ) rules + residual_plot . . . Notice how residuals above/below zero have most points temporally close to it also above/below zero as well, which goes against the independence of observations assumption of OLS ‚ùå. . . üìùIn practice when analyzing time series data the presence of autocorrelation is the rule instead of the exception since in general the factors that contributed to a given observation tend to persist for a while. . . Autoregressive model solution . The autoregressive model specifies that each observation depends linearly on previous observations. . Thus, an autoregressive model of order $p$ ($AR(p)$) can be written as . yt=c+œï1yt‚àí1+‚ãØ+œïpyt‚àíp+œµty_t = c + phi_1 y_{t-1}+ dots + phi_p y_{t-p} + epsilon_tyt‚Äã=c+œï1‚Äãyt‚àí1‚Äã+‚ãØ+œïp‚Äãyt‚àíp‚Äã+œµt‚Äã . Where: . $y_t$: observation at time $t$, . $y_{t-i}$: observation at time $t - i$, . $ phi_i$: coefficient of how much observation $y_{t - i}$ correlates to $y_t$, . $ epsilon_t$: white noise ( $ mathcal{N}(0, sigma¬≤)$ ) at time $t$. . Autocorrelation . To assess how much an observation correlates with past observations it is useful to do an autocorrelation plot as shown below: . sm.graphics.tsa.plot_acf(res.resid, lags=10) plt.show() . . . Partial Autocorrelation . The partial autocorrelation at lag $p$ is the correlation that results after removing the effect of any correlations due to the terms at shorter lags. . sm.graphics.tsa.plot_pacf(res.resid, lags=10) plt.show() . . . Model selection . The theory states that in an autoregressive model its autocorrelation plot should depict an exponential decay and the number of lags $p$ should be taken from the partial autocorrelation chart using its $p$ most relevant lags. Applying the theory to our plots above, we conclude that our model is autoregressive of lag 1 also known as AR(1). . ARIMA . In statistics ARIMA stands for autoregressive integrated moving average model and as can be inferred by the name AR models are as especial case of ARIMA therefore AR(1) is equivalent to ARIMA(1,0,0). . We can model an AR(1) process to our dataset using statsmodels ARIMA as below: . from statsmodels.tsa.arima.model import ARIMA arima_results = ARIMA(df[&quot;Y&quot;], df[[&quot;T&quot;,&quot;D&quot;,&quot;P&quot;]], order=(1,0,0)).fit() print(arima_results.summary()) . Output: . SARIMAX Results ============================================================================== Dep. Variable: Y No. Observations: 48 Model: ARIMA(1, 0, 0) Log Likelihood 18.574 Date: Thu, 30 Dec 2021 AIC -25.148 Time: 01:51:46 BIC -13.921 Sample: 0 HQIC -20.905 - 48 Covariance Type: opg ============================================================================== coef std err z P&gt;|z| [0.025 0.975] const 12.9172 0.279 46.245 0.000 12.370 13.465 T 0.0121 0.016 0.767 0.443 -0.019 0.043 D -0.5510 0.273 -2.018 0.044 -1.086 -0.016 P -0.0238 0.021 -1.155 0.248 -0.064 0.017 ar.L1 0.6635 0.138 4.803 0.000 0.393 0.934 sigma2 0.0267 0.006 4.771 0.000 0.016 0.038 =================================================================================== Ljung-Box (L1) (Q): 1.00 Jarque-Bera (JB): 0.15 Prob(Q): 0.32 Prob(JB): 0.93 Heteroskedasticity (H): 1.44 Skew: -0.05 Prob(H) (two-sided): 0.47 Kurtosis: 3.25 =================================================================================== . The autoregressive model estimates that the bounce rate decreased üîª 0.55% on average and this effect is statistically significant ($P&gt;|t| = 4.4 % $, less than our $ alpha = 5 % $). . However, unlike the previous OLS model, the autoregressive model does not estimate a statistical significance trend of a decrease in bounce rate each week after intervention, which is in line with our expectations. . The models estimates (with counterfactual projections) can be seen in the chart below: . from statsmodels.tsa.arima.model import ARIMA start = 24 end = 48 predictions = arima_results.get_prediction(0, end-1) summary = predictions.summary_frame(alpha=0.05) arima_cf = ARIMA(df[&quot;Y&quot;][:start], df[&quot;T&quot;][:start], order=(1,0,0)).fit() # Model predictions means y_pred = predictions.predicted_mean # Counterfactual mean and 95% confidence interval y_cf = arima_cf.get_forecast(24, exog=df[&quot;T&quot;][start:]).summary_frame(alpha=0.05) # Plot section plt.style.use(&#39;seaborn-whitegrid&#39;) fig, ax = plt.subplots(figsize=(16,10)) # Plot bounce rate data ax.scatter(df[&quot;T&quot;], df[&quot;Y&quot;], facecolors=&#39;none&#39;, edgecolors=&#39;steelblue&#39;, label=&quot;bounce rate data&quot;, linewidths=2) # Plot model mean bounce prediction ax.plot(df[&quot;T&quot;][:start], y_pred[:start], &#39;b-&#39;, label=&quot;model prediction&quot;) ax.plot(df[&quot;T&quot;][start:], y_pred[start:], &#39;b-&#39;) # Plot counterfactual mean bounce rate with 95% confidence interval ax.plot(df[&quot;T&quot;][start:], y_cf[&quot;mean&quot;], &#39;k.&#39;, label=&quot;counterfactual&quot;) ax.fill_between(df[&quot;T&quot;][start:], y_cf[&#39;mean_ci_lower&#39;], y_cf[&#39;mean_ci_upper&#39;], color=&#39;k&#39;, alpha=0.1, label=&quot;counterfactual 95% CI&quot;); # Plot line marking intervention moment ax.axvline(x = 24.5, color = &#39;r&#39;, label = &#39;intervention&#39;) ax.legend(loc=&#39;best&#39;) plt.ylim([10, 15]) plt.xlabel(&quot;Weeks&quot;) plt.ylabel(&quot;Bounce rate (%)&quot;); . . . We can clearly see that the ARIMA(1, 0, 0) model fits our dataset better than the OLS model. . ARIMA residual analysis . The summary of our autoregressive model shows a Prob(JB): 0.93 which is compatible with the null-hypothesis of normaly distributed residuals. ‚úÖ . The Ljung-Box Q test verifies whether the residuals are independently distributed (they exhibit no serial autocorrelation) as $H_0$ (null-hypothesis). As the Prob(Q): 0.32 is way above the standard $ alpha = 0.05$ there is no evidence of serial autocorrelation in the ARIMA residuals. ‚úÖ . Let‚Äôs now take a look at residuals qqplot to check if they follow a normal distribution: . import scipy as sp from statsmodels.graphics.gofplots import qqplot fig, (ax1, ax2) = plt.subplots(1,2, figsize=(16,8)) sm.qqplot(res.resid, sp.stats.t, fit=True, line=&quot;45&quot;, ax=ax1); ax1.set_title(&quot;OLS qqplot&quot;); sm.qqplot(arima_results.resid, sp.stats.t, fit=True, line=&quot;45&quot;, ax=ax2); ax2.set_title(&quot;ARIMA qqplot&quot;); plt.show(); . . . We may observe that the ARIMA(1,0,0) model residuals not only are in general normally distributed as they fit better than the OLS model the theoretical quantiles. ‚úÖ . Summary . A/B tests are a the most powerful and trustworthy method to do measure the impact of modifications/changes even before they are fully implemented, which is why they are so widely used. . However, there are some scenarios where A/B tests are not feasible and this is when the knowledge of quasi-experiments becomes valuable to get statistically sound measurements of change impact. . In this post we have shown why an ordinary least square (OLS) linear regression is not a good modeling approach for time series data since they usualy present non-negligible autocorrelation that violates some assumptions of OLS. . We demonstrated with an example how to use python (statsmodels, matplotlib, altair and pandas) to visualize residuals and plot autocorrelation and partial autocorrelations charts to figure out the lag of an autoregressive model and then implemented a ARIMA model using statsmodels to observed a more accurate and precise analysis and how to interpret statsmodels model output for OLS and ARIMA. . We also showed how to plot in a single chart the models estimates (mean and 95% confidence interval) for the time periods before and after intervention and its respective counterfactual. . . References . [1] Shopify Engineering: How to Use Quasi-experiments and Counterfactuals to Build Great Products. . [2] Wikipedia: Interrupted Time Series. . [3] Campbell DT, Stanley JC. Experimental and Quasi-experimental Designs for Research. Boston, MA: Houghton Mifflin, 1963. .",
            "url": "https://www.xboard.dev/fastpages-blog/interrupted-time-series-python-part-I",
            "relUrl": "/interrupted-time-series-python-part-I",
            "date": " ‚Ä¢ Jan 1, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.‚Ü© . 2. This is the other footnote. You can even have a link!‚Ü© .",
            "url": "https://www.xboard.dev/fastpages-blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " ‚Ä¢ Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a ‚Äúlevel 1 heading‚Äù in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here‚Äôs a footnote 1. Here‚Äôs a horizontal rule: . . Lists . Here‚Äôs a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes ‚Ä¶and‚Ä¶ . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote.¬†&#8617; . |",
            "url": "https://www.xboard.dev/fastpages-blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " ‚Ä¢ Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats.¬†&#8617; . |",
          "url": "https://www.xboard.dev/fastpages-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://www.xboard.dev/fastpages-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}